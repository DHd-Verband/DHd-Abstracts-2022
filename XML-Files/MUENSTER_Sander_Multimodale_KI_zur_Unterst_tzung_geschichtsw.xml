<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="DHd2022_232">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title type="full">
                    <title type="main">Multimodale KI zur Unterstützung geschichtswissenschaftlicher Quellenkritik</title>
                    <title type="sub">Ein Forschungsaufriss</title>
                </title>
                <author>
                    <persName>
                        <surname>Muenster</surname>
                        <forename>Sander</forename>
                    </persName>
                    <affiliation>FSU Jena, Germany</affiliation>
                    <email>sander.muenster@uni-jena.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Bruschke</surname>
                        <forename>Jonas</forename>
                    </persName>
                    <affiliation>JMU Wuerzburg, Germany</affiliation>
                    <email>jonas.bruschke@uni-wuerzburg.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Kroeber</surname>
                        <forename>Cindy</forename>
                    </persName>
                    <affiliation>FSU Jena, Germany</affiliation>
                    <email>cindy.kroeber@uni-jena.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Hoppe</surname>
                        <forename>Stephan</forename>
                    </persName>
                    <affiliation>LMU Muenchen, Germany</affiliation>
                    <email>stephan.hoppe@kunstgeschichte.uni-muenchen.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Maiwald</surname>
                        <forename>Ferdinand</forename>
                    </persName>
                    <affiliation>FSU Jena, Germany</affiliation>
                    <email>ferdinand.maiwald@uni-jena.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Niebling</surname>
                        <forename>Florian</forename>
                    </persName>
                    <affiliation>JMU Wuerzburg, Germany</affiliation>
                    <email>florian.niebling@uni-wuerzburg.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Pattee</surname>
                        <forename>Aaron</forename>
                    </persName>
                    <affiliation>LMU Muenchen, Germany</affiliation>
                    <email>aaron.pattee@lmu-muenchen.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Utescher</surname>
                        <forename>Ronja</forename>
                    </persName>
                    <affiliation>FSU Jena, Germany; U. Bielefeld, Germany</affiliation>
                    <email>ronja.utescher@uni-bielefeld.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Zarriess</surname>
                        <forename>Sina</forename>
                    </persName>
                    <affiliation>U. Bielefeld, Germany</affiliation>
                    <email>sina.zarriess@uni-bielefeld.de</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2022-02-12T20:33:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
    <publisher>Universität Potsdam</publisher>
    <address>
        <addrLine>Netzwerk für Digitale Geisteswissenschaften</addrLine>  
        <addrLine>Am Neuen Palais 10</addrLine>
        <addrLine>14469 Potsdam</addrLine>
        <addrLine>Deutschland</addrLine>
    </address>
    <publisher>Fachhochschule Potsdam</publisher>
    <address>
        <addrLine>Kiepenheuerallee 5</addrLine>
        <addrLine>14469 Potsdam</addrLine>
        <addrLine>Deutschland</addrLine>
    </address>
</publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Vortrag</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>KI</term>
                    <term>Quellenkritik</term>
                    <term>Geschichte</term>
                    <term>Kunstgeschichte</term>
                    <term>Multimodalität</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>Datenerkennung</term>
                    <term>Räumliche Analyse</term>
                    <term>Modellierung</term>
                    <term>Visualisierung</term>
                    <term>Bilder</term>
                    <term>Multimedia</term>
                </keywords>
            </textClass>
        <settingDesc><ab n="conference">DHd2022 – "Kulturen des digitalen Gedächtnisses", Potsdam</ab><ab n="paperID">232</ab></settingDesc></profileDesc>
    </teiHeader>
    <text>
        <body>
            <div type="div1" rend="DH-Heading1">
                <head>Einleitung</head>
                <p>Fotografien und andere Abbilder von Architektur dienen in vielen historischen Wissenschaften als Quelle und Grundlage für fach- und theoriespezifische Untersuchungen. So werden zum Beispiel historische Fotoaufnahmen herangezogen, um den Zustand eines Gebäudes zu rekonstruieren oder die Formensprache einer Epoche zu identifizieren. Ausgangspunkt dieser Szenarien aus Architektur-, Kunstgeschichte und Kulturwissenschaften ist eine durch Hilfsmittel der jeweiligen Fächer unterstützte Quellenrecherche und -kritik, auf die weitere Auswertungen und Verwendungen im wissenschaftlichen Kontext aufbauen.</p>
                <p>Obwohl sich KI-basierte Methoden der 
                    <hi rend="italic">Computer Vision</hi> in den letzten Jahren wesentlich weiterentwickelt haben, können diese den Prozess der Quellenrecherche und -kritik bisher allenfalls im Ansatz unterstützen, bspw. für die Exploration von Bildrepositorien oder das Retrieval von Bildern. Dies liegt zum einen daran, dass elementare diesbezügliche Vorgehensweisen zwar gut dokumentiert sind, WissenschaftlerInnen aber sehr individuell vorgehen. Zum anderen ist KI-Bildverarbeitung bisher wenig darauf ausgelegt, bildliche Inhalte multimodal zu kontextualisieren, d.h. verschiedene Quellengattungen wie Bilder und Texte zu kombinieren. Existierende Verfahren der Computer Vision extrahieren rein visuelle Merkmale und klassifizieren diese, während Texte oder Metadaten und darin enthaltenes Wissen wie bspw. Hinweise auf zeitliche Kontexte oder einzelne Motive nicht mit der Analyse verknüpft werden können.
                </p>
                <p>Das BMBF-geförderte Projekt 
                    <hi rend="italic">HistKI</hi> startete im Januar 2021 und will die Unterstützung und Modellierung von Bildquellenrecherche und -kritik als komplexe und grundlegende geschichtswissenschaftliche Arbeitstechnik durch multimodale KI-basierte Verfahren erforschen. Damit verbundene Teilfragen sind beispielsweise: Wie finden und beurteilen Historiker und andere Fachwissenschaftler Bildquellen? Welche generischen Vorgehensweisen und Teilproblemstellungen lassen sich hierfür identifizieren? Wie lässt sich dies mit KI-basierten Ansätzen befördern? Wie wirken sich KI-Techniken auf den geisteswissenschaftlichen Forschungsprozess aus? 
                </p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Forschungsstand</head>
                <p>Ausgangspunkt des Vorhabens ist der geschichtswissenschaftliche Forschungsprozess im Umgang mit Bildquellen. Für ein forschendes Handeln in den historischen Wissenschaften prägend sind einzelne Themenfelder (bspw. Kunst, Technik, Wirtschaft, Politik) sowie die darauf bezogenen Erkenntniszugänge. Leitendes Paradigma ist eine konstruktivistische Problemorientierung und damit eine quellenkritische, gegenstandsbezogene Analyse (Wengenroth, 1998, Reich, 2006). Methodologische Zugänge dazu liefern bspw. Hermeneutik, Semiotik (Holenstein, 1988, Zöllner, 2005) oder Phänomenologie (Prechtl, 2002). Grundsätzlich findet ein Zugang über Quellen statt und die damit verbundene Quellenkritik ist eine grundlegende Vorgehensweise historischer Forschung (Opgenoorth, 1997).</p>
                <p>
                    <hi rend="italic">Modellierung forschenden Handelns</hi>: Eine Systematisierung von digitalem Forschungshandeln in den historischen Wissenschaften erfolgt bspw. aus Perspektive der eScience (Köhler et al., 2016) oder Informationswissenschaften, Ansätze zur Modellierung von Prozessabfolgen forschenden Handelns sind bspw. Forschungsprimitive (Münster and Terras, 2020, Kamposiori and Benardou, 2011). Demgegenüber stehen Ansätze zur sozialwissenschaftlichen Analyse des Informations- und Forschungsverhaltens (Münster et al., 2018, Ying et al., unpublished), bspw. der Science and Technology Studies (STS) u. a. anhand epistemischer Kulturen (Knorr-Cetina and Reichmann, 2015) oder der Wissenschaftsphilosophie anhand der Erkenntnisprozesse (Fleck, 1980, Popper, 1998). Damit gehen Ansätze zur Operationalisierung einerseits von der (1) „mechanistischen“ Idee aus, forschendes Handeln als Abfolge von operationalisierbaren Forschungsschritten (e.g. Forschungsprimitive, eScience) zu betrachten. Andererseits steht (2) die Vorstellung eines geisteswissenschaftlichen Forschungshandelns als „Black Box“ und erfahrungsbasiert, auf implizitem Wissen (Polanyi, 1966) basierend sowie der Wissensgenese als „serendipity“ (e.g. STS). Nicht zuletzt hinsichtlich der Lehrbarkeit haben sich in den bildbezogenen historischen Wissenschaften (3) semi-operationalisierte Zwischenformen etabliert – bspw. die bereits benannte Quellenkritik sowie speziell für Bildmedien die ikonologische Analyse (Panofsky, 1939). Trotz derartiger systematisierender Ansätze erfolgt eine Recherche und kritische Betrachtung von historischen Quellen in der Praxis hochgradig individuell und erfahrungsbasiert (Brieber et al., 2014, Münster et al., 2018). Vor diesem Hintergrund werden KI-basierte Ansätze derzeit vor allem zur Unterstützung von abgegrenzten Teilproblemen, wie Suche nach ähnlichen Bildern (Münster et al., 2019, Bell and Ommer, 2019), die Anreicherung von textuellen Metadaten (Lee and Münster, 2018) sowie Musteranalyse (Kohle, 2018, Klinke, 2016), eingesetzt.
                </p>
                <p>
                    <hi rend="italic">Bildwissenschaftliche Zugänge:</hi> Eine Reihe von aktuellen Publikationen und Initiativen greifen das Zusammenspiel von bildbezogenen historischen Wissenschaften und KI-basierten Forschungsansätzen auf – bspw. der Band „Digital Art History“ (Kuroczynski et al., 2019) sowie das DFG-Schwerpunktprogramm „Das digitale Bild“ (Kohle, 2018). Trotz heterogener Ansätze zur Bildrecherche und Quellenkritik existiert eine Reihe allgemeiner Problemstellungen (Hoppe and Breitling, 2016). HistKI liefert mit seiner inhaltsgetriebenen und forschungsprozessorientierten Fragestellung eine wichtige und komplementäre Grundlage für diese Initiative.
                </p>
                <p>
                    <hi rend="italic">Language &amp; Vision:</hi> Neuere Ansätze der Bildverarbeitung aus dem Bereich des Deep Learning ermöglichen nicht nur eine bessere Objekterkennung, sondern erweisen sich als besonders geeignet für 
                    <hi rend="italic" xml:space="preserve">transfer learning </hi>an der Schnittstelle von Bild- und Sprachverarbeitung. Dabei werden zum Beispiel semantische Repräsentationen wie 
                    <hi rend="italic">word</hi> oder 
                    <hi rend="italic">sentence embeddings</hi>, die aus Texten gelernt werden, anhand von multimodalen Daten wie Bildbeschreibungen mit visuellen Repräsentationen angereichert. Damit ist das Vokabular eines Objekterkennungssystems aus der Bildverarbeitung, das typischerweise auf eine mehr oder weniger große Menge an Kategorien festgelegt ist, wesentlich erweitert und es können semantische Bezüge zwischen visuellen Objekten und einer großen Menge an Wörtern oder Phrasen erfasst werden. Beispielsweise gibt es aktuelle Untersuchungen zur automatischen Erkennung eines inhaltlichen Bezugs zwischen Bildern und Textpassagen, (Hessel et al., 2019). Diese Art von Modellierung stellt einen Schritt in Richtung der Herstellung eines gemeinsamen Kontexts von Bild und Text dar. Für die multimodale Extraktion von Informationen aus fachwissenschaftlichen Texten ist es jedoch notwendig, solche referentiellen Beziehungen zwischen Text- und Bild-Teilen auch feingliedriger zu erfassen (Utescher and Zarrieß, 2021).
                </p>
                <p>
                    <hi rend="italic">Segmentierung und Objekterkennung:</hi> Die Grundlagen für die Rekonstruktion aus historischen Fotografien bilden die analytischen Verfahren der Photogrammetrie, d.h. die Gewinnung zwei- und dreidimensionaler Objektgeometrien aus den zweidimensionalen Bildinformationen (Wiedemann et al., 2000). Photogrammetrische Verfahren liefern auch räumliche Relationen zwischen Fotografien und dreidimensionalen Objektgeometrien. Aus durch bildgebende Verfahren entstandenen Datensätzen lassen sich einfache Strukturen (Vosselman et al., 2004), aber auch komplexe Objekte wie Gebäude (Li et al., 2016, Agarwal et al., 2011) automatisch segmentieren sowie zuordnen (Martinovic et al., 2015, Hackel et al., 2016). Dabei können auch Rückschlüsse darauf gezogen werden, welche Bildteile welche Teile der 3D-Objektgeometrien referenzieren (Xie et al., 2016, Vosselman et al., 2004). Maschinelles Lernen (ML) spielt eine zunehmend größere Rolle bei der Segmentierung von Bild und der Objekterkennung (Minaee et al., 2021, Jiao et al., 2019) sowie der Strukturerkennung in 3D-Daten (Guo et al., 2020). Insbesondere vor dem Hintergrund der Anwendung von ML Ansätzen auf historische Quellen bestehen spezifische Herausforderungen in zumeist sehr kleinen und qualitativ heterogenen Ausgangsdaten (Fiorucci et al., 2020).
                </p>
                <p>
                    <hi rend="italic">Verortung und Exploration:</hi> Ein besonderes Verhältnis besteht zwischen Bildquellen und 3D-Modellen. Im BMBF-Projekt 
                    <hi rend="italic">HistStadt4D</hi> wurden exemplarisch Methoden zur automatischen Verortung von Fotografien entwickelt (Maiwald and Maas, 2021) und diese Daten in einer virtuellen 4D-Forschungsumgebung zugänglich gemacht (Bruschke et al., 2018, Maiwald et al., 2019) sowie quantitative raumbezogene Analysemethoden evaluiert (Dewitz et al., 2019). Mit Hilfe von Verfahren des maschinellen Lernens sollen in 
                    <hi rend="italic">HistKI</hi> zudem Objektquellen und Textquellen (z.B. Bildunterschriften) verknüpft werden, um in Zukunft eine detaillierte Kontextualisierung und Verortung der Fotografien und Texte zu erlauben und damit über bisherige Methoden des 
                    <hi rend="italic">distant viewing</hi> (Arnold and Tilton, 2019) hinauszugehen.
                </p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Forschungsaufriss</head>
                <p>Im Folgenden soll ein kurzer Überblick über erste Forschungsschritte im Projekt gegeben werden.</p>
                <figure>
                    <graphic n="1001" width="15.973777777777778cm" height="4.321527777777778cm" url="Pictures/d900b2965367aa1cdef704ef38c05f32.png" rend="inline"/>
                    <head>Abb. 1: Identifizierte Architekturelemente im Bild (links), im Text (mitte) und im 3D-Modell (rechts) am Beispiel des Kronentors des Dresdner Zwingers.</head>
                </figure>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Identifikation von Forschungsszenarien</head>
                <p>Der Einsatz von multimodalen KI-Techniken wird anhand von ausgewählten Szenarien untersucht, in denen Informationen aus Bildern, Texten und 3D-Modellen zur Beschreibung von Wissen über Architekturobjekte und städtebaulichen Ensembles für einen Analyseprozess mit¬einander verschränkt werden können. In Voruntersuchungen wurde dafür mit Hilfe qualitativer Expertenbefragungen und Workshops eine Reihe generischer Szenarien identifiziert (Kröber, 2021, Dewitz et al., 2019) und hinsichtlich einer Relevanz und Umsetzbarkeit priorisiert. Aus den ermittelten ca. 20 Szenarien wurden für eine erste Projektphase die medienübergreifende Identifikation von Objektbeschreibungen („Welche Bilder, Texte, 3D-Daten beschreiben dasselbe Objekt?“) sowie die Analyse von Beschreibungen (bspw.: „Wie kann die Datierung von historischen Bild- und Textdarstellungen von Objekten durch eine multimodale Validierung, bspw. anhand bereits datierter Medien, unterstützt werden?“) als Forschungsschwerpunkte ausgewählt.</p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Medienübergreifende Klassifikation</head>
                <p>Die medienübergreifende Verarbeitung von 3D-Modellen, Bild- und Textquellen in einem möglichst universellen Format ist eine der zentralen Herausforderungen des Projekts. Eine diesbezüglich wichtige Voraussetzung ist es, medienübergreifend Elemente zu identifizieren und zu benennen. Die Entwicklung von domänenspezifischen Ontologien für architekturgeschichtliche Inhalte ist aktuell ein Schwerpunktthemen und wird von einer Vielzahl von Initiativen vorangebracht – beispielhaft seien hier ICONCLASS<ref target="ftn1" n="1"/>, Getty Art &amp; Architecture Thesaurus (AAT), als generische Ontologie Wikibase<ref target="ftn2" n="2"/> sowie als übergreifende Referenzontologie CIDOC-CRM benannt. Als Grundgerüst für die strukturierende Beschreibung von Architekturelementen dient in unserem Projekt das AAT, welches trotz aktuell noch vorhandener Defizite hinsichtlich der deutschen Übersetzung durch eine umfassende und an einer kunsthistorischen Typisierung orientierte Struktur eine gute Ausgangsbasis für unser Projekt verspricht. Dabei wird von uns zunächst nur die gemessen am Gesamtvokabular kleine Untergruppe 
                    <hi rend="italic">architectural elements</hi><ref target="ftn3" n="3"/> verwendet. Die identifizierten Elemente im Text (einzelne Wörter oder Wortgruppen), Bild (polygonale Bildausschnitte) und 3D-Modell (einzelne Teilgruppenobjekte) werden den Konzepten des AAT zugeordnet (Abb. 1). Je nach Quellentyp sind dabei verschiedene Verfahren, wie z.B. semantic segmentation, named entity recognition (NER), und discourse parsing, notwendig, sowohl was die Identifizierung der Konzepte als auch die semantische Anreicherung betrifft. Als Nächstes müssen die identifizierten Konzepte zwischen den verschiedenen Quellen in einen Zusammenhang gebracht werden. Dazu werden die Identifier der AAT-Konzepte abgeglichen sowie meta-klassifiziert (z.B. Ionische Säule <hi rend="math">→</hi> Säule). Um mehrere Instanzen einer solchen Klasse zu unterscheiden (bspw. einzelne Säulen in einer Säulenreihe) werden die einzelnen Instanzen mit einer Identifikationsnummer versehen. Das AAT liefert ein detailliertes Vokabular zur Klassifizierung, reicht aber derzeit nicht aus, um alle Informationen, insbesondere Informationen aus Textquellen, vollständig abzubilden. Es müssen daher weitere Merkmale identifiziert werden, die das AAT nicht repräsentieren kann, wie z.B. Lagebeziehungen („Ostflügel“, „Westfassade“) oder Eigennamen.
                </p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Multimodale Datenanreicherung</head>
                <p>In einem weiteren Schritt werden Ansätze zur multimodalen Datenanreicherung und -validierung entwickelt. So werden beispielsweise im 3D-Raum in Relation zum 3D-Modell verortete Bilder verwendet, um eine im 3D-Modell vorliegende Strukturierung auf Bilddokumente zu übertragen (Niebling et al., 2018). Durch den räumlichen Zusammenhang zwischen Bild und Modell können Annotationen von bereits semantisch angereicherten 3D-Modellen bzw. ihrer einzelnen Bauteile auf die entsprechenden Bildquellen projiziert, sowie auch von bereits annotierten Bildquellen auf 3D-Modelle zurückübertragen werden. Der 3D-Raum bietet zudem erweiterte Möglichkeiten, Lagebeziehungen zwischen (Teil-)Objekten herauszufinden. Die erkannten Zusammenhänge und semantischen Beziehungen werden in einer Ontologie gespeichert.</p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Ausblick</head>
                <p>Quo vadis? Während im aktuellen Projektstadium mit manuell klassifizierten Quellen gearbeitet wird, ist ein nächster Schritt ist die Untersuchung von Ansätzen zur automatisierten Erkennung und Annotation von Objektbestandteilen. Hier werden schwerpunktmäßig KI-basierte Modelle verwendet, die auf die jeweiligen Modalitäten (3D-Modelle, Bilder, (multimodale) Texte) spezialisiert sind – beispielsweise die bereits benannten computerlinguistischen Verfahren zur Texterkennung sowie ein modulares Object Retrieval für die Erkennung von architektonischen Strukturen in Bildern (Münster et al., in print) und die in Schritt 3 ausgeführte Übertragung dieser Segmentierung auf 3D-Modelle.</p>
                <p>Darauf aufbauend erfolgen in weiteren zukünftigen Schritten einerseits die Verbesserung und multimodale Validierung von Erkennungsqualitäten sowie die Entwicklung eines Demonstrators zur Nutzererprobung mit Historiker*innen.</p>
                <p>Dies dient auch als Grundlage einer Bewertung von KI-Ansätzen für die historische Forschung. Hier gilt es beispielsweise, die Diskrepanz zwischen dem großen Datenbedarf der KI-Modelle und der Komplexität des geschichtswissenschaftlichen Expertenwissens zu untersuchen und damit zu bewerten, wie effektiv existierende KI-Modelle mit begrenzten Datenmengen für Teilaspekte der (architektur-)geschichtlichen Quellenkritik eingesetzt werden können.</p>
            </div>
        </body>
        <back><div type="notes"><note place="foot" xml:id="ftn1" n="1">
                            <ref target="http://www.iconclass.org/rkd/61F/">http://www.iconclass.org/rkd/61F/</ref> sowie 
                            <ref target="http://www.iconclass.org/rkd/47/">http://www.iconclass.org/rkd/47/</ref>, 15.07.2021.
                        </note><note place="foot" xml:id="ftn2" n="2">
                            <ref target="https://www.wikimedia.de/projects/wikibase/">https://www.wikimedia.de/projects/wikibase/</ref>, 15.07.2021
                        </note><note place="foot" xml:id="ftn3" n="3">
                            <ref target="http://vocab.getty.edu/aat/300000885">http://vocab.getty.edu/aat/300000885</ref>
                            <hi rend="Hyperlink" xml:space="preserve">, </hi>15.07.2021.
                        </note></div>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliographie</head>
                    <bibl>
                        <hi rend="bold">Agarwal, S./ Furukawa, Y./ Snavely, N./ Simon, I./ Curless, B./ Seitz, S. M. / Szeliski, R.</hi> (2011). Building rome in a day. 
                        <hi rend="italic">Communications of the ACM</hi>, 54, 105.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Arnold, T. / Tilton, L.</hi> (2019). Distant viewing: analyzing large visual corpora. 
                        <hi rend="italic">Digital Scholarship in the Humanities.</hi>
                    </bibl>
                    <bibl>
                        <hi rend="bold">Bell, P. / Ommer, B.</hi> (2019). Computer Vision und Kunstgeschichte – Dialog zweier Bildwissenschaften. In: KUROCZYNSKI, P., BELL, P. &amp; DIECKMANN, L. (eds.) 
                        <hi rend="italic">Digital Art History</hi>. Heidelberg.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Brieber, D./ Nadal, M./ Leder, H. / Rosenberg, R.</hi> (2014). Art in Time and Space: Context Modulates the Relation between Art Experience and Viewing Time. 
                        <hi rend="italic">PloS ONE</hi>, 9, e99019.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Bruschke, J./ Maiwald, F./ Münster, S. / Niebling, F.</hi> (2018). Browsing and Experiencing Repositories of Spatially Oriented Historic Photographic Images. 
                        <hi rend="italic">Studies in Digital Heritage</hi>, 2, 138-149.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Dewitz, L./ Kröber, C./ Messemer, H./ Maiwald, F./ Münster, S./ Bruschke, J. / Niebling, F</hi>. (2019). HISTORICAL PHOTOS AND VISUALIZATIONS: POTENTIAL FOR RESEARCH. 
                        <hi rend="italic">Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci</hi>., XLII-2/W15, 405-412.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Fiorucci, M./ Khoroshiltseva, M./ Pontil, M./ Traviglia, A./ Del Bue, A. / James, S.</hi> (2020). Machine Learning for Cultural Heritage: A Survey. 
                        <hi rend="italic">Pattern Recognition Letters</hi>, 133, 102–108.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Fleck, L.</hi> (1980). 
                        <hi rend="italic">Entstehung und Entwicklung einer wissenschaftlichen Tatsache. Einführung in die Lehre vom Denkstil und Denkkollektiv</hi>, Frankfurt a. M., Suhrkamp.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Guo, Y./ Wang, H./ Hu, Q./ Liu, H./ Liu, L. / Bennamoun, M.</hi> (2020). Deep Learning for 3D Point Clouds: A Survey. 
                        <hi rend="italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</hi>, 1-1.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Hackel, T./ Wegner, J. D. / Schindler, K.</hi> (2016). Fast semantic segmentation of 3D point clouds with strongly varying density. 
                        <hi rend="italic">ISPRS Annals</hi>, 3, 177–184.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Hessel, J./ Lee, L. / Mimno, D</hi>. (2019). Unsupervised Discovery of Multimodal Links in Multi-image, Multi-sentence Documents. 
                        <hi rend="italic">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</hi> (EMNLP-IJCNLP).
                    </bibl>
                    <bibl>
                        <hi rend="bold">Holenstein, E.</hi> (1988). 
                        <hi rend="italic">Linguistik, Semiotik, Hermeneutik</hi>, Frankfurt am Main.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Hoppe, S. / Breitling, S.</hi> (2016). Virtual Palaces, Digital Images – an Introduction. In: S., H. &amp; S., B. (eds.) 
                        <hi rend="italic">Virtual Palaces, Part II: Lost Palaces and their Afterlife. Virtual Reconstruction between Science and Media</hi>. Heidelberg: arthistoricum.net.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Jiao, L./ Zhang, F./ Liu, F./ Yang, S./ Li, L./ Feng, Z. / Qu, R.</hi> (2019). A Survey of Deep Learning-Based Object Detection
                        <hi rend="italic">. IEEE Access</hi>, 7, 128837-128868.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Kamposiori, C. / Benardou, A.</hi> (2011). Collaboration in Art Historical Research: Looking at primitives. 
                        <hi rend="italic">Z. Kunstgeschichte</hi> [Online]. Available: Available at 
                        <ref target="http://www.kunstgeschichte-ejournal.net/157/">http://www.kunstgeschichte-ejournal.net/157/</ref> (accessed 17 June 2011).
                    </bibl>
                    <bibl>
                        <hi rend="bold">Klinke, H.</hi> (2016). Big Image Data within the Big Picture of Art History.
                        <hi rend="italic" xml:space="preserve"> Int. J. Digital Art History</hi>, 2.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Knorr-Cetina, K. / Reichmann, W.</hi> (2015). Epistemic Cultures. 
                        <hi rend="italic">International Encyclopedia of the Social &amp; Behavioral Sciences</hi>. Amsterdam: Elsevier.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Kohle, H.</hi> (2018). 
                        <hi rend="italic">Initiative zur Einrichtung eines Schwerpunktprogramms. Das digitale Bild</hi>.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Köhler, T./ Günther, F./ Herbst, S./ Münster, S. / Fischer, H</hi>. (2016). 
                        <hi rend="italic">Abschlussbericht im Projekt SUFES. Unterstützungsangebote und Strukturen im Themenfeld eScience</hi>, Dresden.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Kröber, C.</hi> (2021). German Art History Students’ use of Digital Repositories: an Insight 
                        <hi rend="italic">Papers Proceedings, Diversity, Divergence, Dialogue</hi>. Cham: Springer LNCS.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Kuroczynski, P./ Bell, P. / Dieckmann, L</hi>. (eds.) 2019. 
                        <hi rend="italic">Digital Art History</hi>, Heidelberg.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Lee, E. / Münster, S.</hi> (2018). Fishing for Knowledge in a Sea of Data (Session
                        <hi rend="italic">). 24th Annual Meeting of the European Association of Archaeologists</hi>, 2018 Barcelona.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Li, M./ Nan, L./ Smith, N. / Wonka, P</hi>. (2016). Reconstructing building mass models from UAV images
                        <hi rend="italic">. Computers &amp; Graphics</hi>, 54, 84-93.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Maiwald, F./ Henze, F./ Bruschke, J. / Niebling, F.</hi> (2019). Geo-Information Technologies for a Multimodal Access on Historical Photographs and Maps for Research and Communication in Urban History. 
                        <hi rend="italic">Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.</hi>, XLII-2/W11, 763-769.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Maiwald, F. / Maas, H.-G.</hi> (2021). An automatic workflow for orientation of historical images with large radiometric and geometric differences. 
                        <hi rend="italic">The Photogrammetric Record</hi>, 36, 77-103.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Martinovic, A./ Knopp, J./ Riemenschneider, H. / Van Gool, L.</hi> (2015). 3d all the way: Semantic segmentation of urban scenes from start to end in 3d
                        <hi rend="italic">. IEEE Computer Vision &amp; Pattern Recognition</hi>. 4456–4465.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Minaee, S./ Boykov, Y. Y./ Porikli, F./ Plaza, A. J./ Kehtarnavaz, N. / Terzopoulos, D.</hi> (2021). Image Segmentation Using Deep Learning: A Survey
                        <hi rend="italic">. IEEE Transactions on Pattern Analysis and Machine Intelligence</hi>, 1-1.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Münster, S./ Apollonio, F./ Bell, P./ Kuroczynski, P./ Lenardo, I. D./ Rinaudo, F. / Tamborrino, R.</hi> (2019). Digital Heritage meets Digital Humanities. 
                        <hi rend="italic">ISPRS Archives</hi>, XLII-2/W15, 813–820.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Münster, S./ Bruschke, J./ Maiwald, F. / Kleiner, C.</hi> (in print). Software and content design of a browser-based mobile 4D VR application to explore historical city architecture. 
                        <hi rend="italic">Proceedings of the 3rd Workshop on Structuring and Understanding of Multimedia heritAge Contents</hi>.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Münster, S./ Kamposiori, C./ Friedrichs, K. / Kröber, C.</hi> (2018). Image Libraries and their Scholarly Use in the Field of Art and Architectural History
                        <hi rend="italic">. Int. J. Digital Libraries</hi>, 19, 367–383.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Münster, S. / Terras, M.</hi> (2020). The visual side of digital humanities. A survey on topics, researchers and epistemic cultures in visual digital humanities. 
                        <hi rend="italic">Digital Scholarship in the Humanities</hi>, 35, 366–389.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Opgenoorth, E.</hi> (1997). 
                        <hi rend="italic">Einführung in das Studium der neueren Geschichte</hi>, Paderborn.
                    </bibl>
                    <bibl>Panofsky, E. (1939). 
                        <hi rend="italic">Studies in Iconology. Humanistic Themes In the Art of the Renaissance</hi>, Oxford, Oxford University Press.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Polanyi, M.</hi> (1966). 
                        <hi rend="italic">The tacit dimension</hi>, Chicago, University of Chicago Press.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Popper, K.</hi> (1998). 
                        <hi rend="italic">Objektive Erkenntnis. Ein evolutionärer Entwurf</hi>, Hamburg, Hoffmann und Campe.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Prechtl, P.</hi> (2002). 
                        <hi rend="italic">Edmund Husserl zur Einführung</hi>, Hamburg.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Reich, K.</hi> (2006). 
                        <hi rend="italic">Konstruktivistische Ansätze in den Sozial- und Kulturwissenschaften. Konstruktivistische Didaktik: Lehr-und Studienbuch mit Methodenpool</hi>. Beltz.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Utescher, R. / Zarrieß, S.</hi> (2021). What Did This Castle Look like before? Exploring Referential Relations in Naturally Occurring Multimodal Texts. In 
                        <hi rend="italic">Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge</hi> (LANTERN).
                    </bibl>
                    <bibl>
                        <hi rend="bold">Vosselman, G./ Gorte, B. G./ Sithole, G. / Rabbani, T.</hi> (2004). Recognising structure in laser scanner point clouds. 
                        <hi rend="italic">ISPRS Archives</hi>, 46, 33-38.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Wengenroth, U.</hi> (1998). 
                        <hi rend="italic">Was ist Technikgeschichte?</hi>, o. Ort.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Wiedemann, A./ Hemmleb, M. / Albertz, J</hi>. (2000). Reconstruction of historical buildings based on images from the Meydenbauer archives
                        <hi rend="italic">. ISPRS Archives</hi>, XXXIII, 887–893.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Xie, J./ Kiefel, M./ Sun, M. T. / Geiger, A.</hi> (2016). Semantic instance annotation of street scenes by 3d to 2d label transfer. 
                        <hi rend="italic">IEEE Computer Vision &amp; Pattern Recognition</hi>. 3688-3697.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Ying, S./ Münster, S./ Köhler, T. / Sommer, C.</hi> (unpublished). A look at the research on design ideas generation in industrial design: Review of literature from 2007 to 2016
                        <hi rend="italic">. Int. J. of Design Creativity &amp; Innovation</hi>.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Zöllner, H.-B.</hi> (2005). 
                        <hi rend="italic">Hermeneutischer Zirkel und hermeneutische Differenz Perspektivität und Objektivität.</hi>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
